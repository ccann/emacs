Require the relevant libs and define a function to create the spark
configuration object which contains information about your application and
tells Spark how to access your cluster.

#+BEGIN_SRC clojure
(ns tf-idf.core
  (:require [clojure.string :as s]
            [sparkling.conf :as conf]
            [sparkling.core :as spark]
            [sparkling.destructuring :as s-de]
            [clojure.pprint :as pp]))

(defn make-spark-context []
  (let [c (-> (conf/spark-conf)
              (conf/master "local[*]")
              (conf/app-name "tfidf"))]
    (spark/spark-context c)))
#+END_SRC

#+BEGIN_SRC clojure
(->> (spark/text-file sc "data.txt") ; text-file RDD (coll of lines)
     (spark/flat-map (fn [line] (s/split line #" "))) ; split each line by whitespace into a coll of words
     (spark/map-to-pair (fn [word] (spark/tuple word 1)))  ; create PairRDD of
     (spark/reduce-by-key +)
     spark/sort-by-key
     (spark/map (s-de/key-value-fn (fn [k v] [k v])))
     spark/collect
     pp/pprint)
#+END_SRC



