* MapReduce
- MapReduce : a programming model for processing and generating large data sets
  with a parallel, distributed algorithm on a cluster.
- the focus is scalability and fault-tolerance.
- Map() : filtering and sorting procedure
- Reduce() : summary operating (reduction to a datum)
- map and reduce are sort of similar to =map= and =reduce= of functional
  programming

* Docker
- targeting cluster management
- "Worked fine in Dev! Ops problem now!"
- OS-level virtualization: provide a virtual operating system (e.g. Ubuntu)
  with dependencies for your project installed already.
- running them all on container-optimized images on EC2 via dchq
- DCHQ : cloud-based collaborative developer platform that accelerates
  container-based app development for large-scale enterprises

* Columnar Databases
- e.g. Amazon Redshift
- [[http://stackoverflow.com/questions/2133017/what-is-a-columnar-database][wtf are these]]


* Apache Hadoop
- Storage (HDFS) and processing (MapReduce)
- mostly Java, open-source
- Fundamentally just a filesystem
- Whatever you can store in a file, you can store in Hadoop
- CANNOT change files. Append-only.
- Store data now, process it later.
- Batch processing : Batch processing is the execution of a series of programs
  ("jobs") on a computer without manual intervention. All input parameters are
  predefined through scripts, command-line arguments, control files, or job
  control language.
- Not low-latency. Designed for batch processing.
- Hadoop MapReduce -> JVM -> HDFS -> Apache Tools (e.g. YARN) -> Linux Kernel
- no notion of job pipeline
- Moves the /processing/ to the data instead of vice-versa
- Hive : SQL-like interface to HDFS

** Clustering
- YARN :: job-scheduling handler and cluster-resource manager
- Zookeeper :: highly-reliable configuration synchronization

** Hadoop MapReduce
- Moves the code to the data
- JobTracker : master service to monitor jobs
- TaskTracker : multiple services to run tasks
- A job contains many tasks
- Use Fair Schedule not FIFO scheduler (default)

** HDFS
- A distributed file-system that stores data on the commodity machines
- looks like a Unix filesystem, but it's distributing data blocks across
  servers.
- HDFS is not designed for collaboration
- stores files across servers (nodes) (very large files; many many files)

*** NameNode
- Master NameNode : know where data blocks live (point of failure)
- takes the file and puts it somewhere on a data node
- standalone server, needs memory (all the box's memory)
- Checkpoint Node : secondary NameNode. saves namespace as a "checkpoint"
- NameNode High-Availability : two redundant NNs. To reduce point of failure.

*** DataNode
- stores blocks on local disk
- checksums
- sends heartbeats/block reports to NameNode
- clients connect to DataNodes for I/O



* Pachyderm
- New improvement on Hadoop
- *Pachyderm MapReduce* -> Docker -> *Pachyderm File System (PFS)* -> CoreOS
  (Fleet, Etcd) -> Linux Kernel
- Pachyderm Job : HTTP server inside a Docker container
- Data -- HTTP --> Docker container -- results --> filesystem
- if it fits in a docker container, you can use it for MapReduce
- creates a DAG for all jobs and their deps. Schedules the pipeline. 
- "Speaks in diffs": which data have changed, which parts of the pipeline need
  to be rerun.

** Clustering
- CoreOS tools: Fleet and Etcd (YARN and Zookeeper analogs)
- Fleet : scheduler that figures out where to run services based on resource
  availability.
- Etcd : fault-tolerant datastore that stores configuration info and dictates
  machine behavior during a net split.

* Onyx
- Onyx : cloud scale fault tolerant distributed data processing framework for
  Clojure.
- Early work, alpha (AFAICT)
- Created by some guy
- realtime event stream processing
- continuous computation
- data transformation
- batch and stream processing hybrid
- /Specification/ of a distributed computation: structure and flow
- /Mechanism of execution/ of a distributed computation: concrete building
  blocks
- Onyx imposes a hard divide between these two concepts.

** onyx-starter
- segment : data structure: map. Ingested and emitted.
- catalog : bind the names of the workflow (specification)
- type =:function= takes a segment, returns a segment or =seq= of segments

* Amazon Redshift
- petabyte scale data warehousing solution

* Server Cluster
- a collection of servers (each server is a Node) that communicate with each
  other to make some services available to clients.

* H2
- the Java SQL database
- Very fast, open source, JDBC API.
- Embedded and server modes; in-memory databases
- Browser-based Console application
- Small footprint: around 1.5 MB jar file size

* Interpolation (NYC to LON)
- Using Bezier curves to interpolate between data points the path of a vessel. 
- Each point is actually a vector (x, y, heading, speed)
- The uncertainty at each point can be problematic because we want to use
  information about historical paths to aid specific pathing, but at the same
  time we want to detect anomalies.

* Cloud Computing Business Models
- IaaS :: Infrastructure as a Service. A type of cloud-service model where a
          company provides physical or virual machines.
- SaaS :: Software as a Service. Provide access to application software and
          databases.
- PaaS :: Platform as a Service. Deliver a computing platform typically
          including operating system, programming language execution
          environment, database, and web server. (e.g. Microsoft Azure, Google
          App Engine)

* Microservices
- [[http://microservices.io/patterns/microservices.html][Useful Article]]
- "Microservice Architecture" has sprung up over the last few years to describe
  a particular way of designing software applications as suites of
  independently deployable services.
** Microservice
*** Pros
- relatively small, faster
- independent deploys
- faster development, easier to scale
- fault isolation
- independent development and deploys
*** Cons
- complexity of a distributed system
- deployment and operational complexity
- increased memory consumption

* Apache Accumulo
- robust, scalable, high performance data storage and retrieval system
- NoSQL
- key/value store
- sorted
- distributed
- based on Google's BigTable design and is built on top of Apache Hadoop,
  Zookeeper, and Thrift.
- security, performance and flexibility


* Cloudera
- Manage your AWS instances


* Amazon Web Services (AWS)
* Amazon S3 (Simple Storage Service)
* Amazon Redshift
* Amazon EC2 (Elastic Compute Cloud)
* Amazon EBS (Elastic block store)
* Consensus Algorithms ([[https://raftconsensus.github.io/][Raft]], Paxos) -- servers agreeing on values


* RabbitMQ
- An open-source message broker software. Implements Advanced Message Queuing
  Protocol (AMQP) written in Erlang


* Nautical Terms (etc.)
- AIS :: Automatic Identification System. An automatic tracking system used on
         ships and by vessel traffic services (VTS) for identifying and
         locating vessels by electronically exchanging data with other nearby
         ships, AIS base stations, and satellites.
- WPI :: World port index
- port of call (port call) :: intermediate stop for a ship. Might take on
     supplies or fuel, or unload cargo.

- MMSI ::  9-digit Maritime Mobile Service Identity. A unique ID for every AIS
           station

- NMEA :: National Marine Electronics Association
* AWS Credentials
- Command Line:
Access Key ID: AKIAIPYTAVVUOEQTK4OA Secret Access
Key: iK5lXuPLAf7Bk8tERsSttRA1TYfVrmmPS/DVj3dB

- Web: account: weft user: cody

* SSH to nutbox
#+BEGIN_SRC sh
#        private key        public DNS
$ ssh -i nutbox-keypair.pem ubuntu@ec2-52-11-208-7.us-west-2.compute.amazonaws.com
$ mosh --ssh="ssh -i nutbox-keypair.pem" ubuntu@ec2-52-11-208-7.us-west-2.compute.amazonaws.com
#+END_SRC



  
  







* Data Sources
- AIS
- Journal of Commerce
